from tokenizer.TextTokenizer import TextTokenizer

def main():
    text = 'My Name is Piyush üòÇ ‚ù§Ô∏è Khandelwal üòé. I\'m an software developer Hanji üíª .';

    hindi_text = '‡§®‡§Æ‡§® ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§≤‡§°‡§º‡§ï‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à';

    hindi_tokenizer_text(hindi_text);

    eng_tokenizer_text(text)

def eng_tokenizer_text(text):
    print(text);
    tokenizer = TextTokenizer(text, 'english');

    encodings = tokenizer.encode();
    print(encodings)

    real_text = tokenizer.decode(encodings);
    print(real_text);

def hindi_tokenizer_text(text):
    print(text);
    tokenizer = TextTokenizer(text, 'hindi');

    encodings = tokenizer.encode();
    print(encodings)

    real_text = tokenizer.decode(encodings);
    print(real_text);

    print(tokenizer.get_vocab_size())

if __name__ == "__main__":
    main()
